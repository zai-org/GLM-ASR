# GLM-ASR

[Readme in English](README.md)

<div align="center">
<img src=resources/logo.svg width="20%"/>
</div>
<p align="center">
    ğŸ‘‹ åŠ å…¥æˆ‘ä»¬çš„ <a href="resources/WECHAT.md" target="_blank">å¾®ä¿¡</a> ç¤¾åŒº
</p>

## æ¨¡å‹ä»‹ç»

**GLM-ASR-Nano-2512** æ˜¯ä¸€æ¬¾é²æ£’çš„å¼€æºè¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼Œå‚æ•°é‡ä¸º **1.5B**ã€‚
è¯¥æ¨¡å‹ä¸“ä¸ºåº”å¯¹çœŸå®ä¸–ç•Œçš„å¤æ‚åœºæ™¯è€Œè®¾è®¡ï¼Œåœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­è¶…è¶Š OpenAI Whisper V3ï¼ŒåŒæ—¶ä¿æŒç´§å‡‘çš„æ¨¡å‹è§„æ¨¡ã€‚

æ ¸å¿ƒèƒ½åŠ›åŒ…æ‹¬ï¼š

* **å“è¶Šçš„æ–¹è¨€æ”¯æŒ**
  é™¤æ ‡å‡†æ™®é€šè¯å’Œè‹±è¯­å¤–ï¼Œæ¨¡å‹é’ˆå¯¹**ç²¤è¯­**åŠå…¶ä»–æ–¹è¨€è¿›è¡Œäº†æ·±åº¦ä¼˜åŒ–ï¼Œæœ‰æ•ˆå¡«è¡¥äº†æ–¹è¨€è¯­éŸ³è¯†åˆ«é¢†åŸŸçš„ç©ºç™½ã€‚

* **ä½éŸ³é‡è¯­éŸ³é²æ£’æ€§**
  ä¸“é—¨é’ˆå¯¹**"ä½è¯­/è½»å£°"**åœºæ™¯è¿›è¡Œè®­ç»ƒï¼Œèƒ½å¤Ÿæ•æ‰å¹¶å‡†ç¡®è½¬å½•ä¼ ç»Ÿæ¨¡å‹éš¾ä»¥è¯†åˆ«çš„æä½éŸ³é‡éŸ³é¢‘ã€‚

* **SOTA æ€§èƒ½**
  åœ¨åŒç±»å¼€æºæ¨¡å‹ä¸­å®ç°**æœ€ä½å¹³å‡é”™è¯¯ç‡ (4.10)**ï¼Œåœ¨ä¸­æ–‡åŸºå‡†æµ‹è¯•ï¼ˆWenet Meetingã€Aishell-1 ç­‰ï¼‰ä¸­å±•ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚

## åŸºå‡†æµ‹è¯•

æˆ‘ä»¬å°† GLM-ASR-Nano ä¸ä¸»æµå¼€æºå’Œé—­æºæ¨¡å‹è¿›è¡Œäº†å¯¹æ¯”è¯„æµ‹ã€‚ç»“æœè¡¨æ˜ï¼Œ**GLM-ASR-Nano (1.5B)** è¡¨ç°ä¼˜å¼‚ï¼Œå°¤å…¶åœ¨å¤æ‚å£°å­¦ç¯å¢ƒä¸‹ä¼˜åŠ¿æ˜æ˜¾ã€‚

![bench](resources/bench.png)

è¯´æ˜ï¼š

* Wenet Meeting åæ˜ äº†åŒ…å«å™ªå£°å’Œè¯­éŸ³é‡å çš„çœŸå®ä¼šè®®åœºæ™¯ã€‚
* Aishell-1 æ˜¯æ ‡å‡†æ™®é€šè¯åŸºå‡†æµ‹è¯•é›†ã€‚

## æ¨¡å‹ä¸‹è½½

| Model             | Download Links                                                                                                                                 |
|-------------------|------------------------------------------------------------------------------------------------------------------------------------------------|
| GLM-ASR-Nano-2512 | [ğŸ¤— Hugging Face](https://huggingface.co/zai-org/GLM-ASR-Nano-2512)<br>[ğŸ¤– ModelScope](https://modelscope.cn/models/ZhipuAI/GLM-ASR-Nano-2512) |

+ è¯·æ³¨æ„ï¼Œé€‚é…`transformers`å’Œ`SGLang`åï¼Œæ¨¡å‹æƒé‡æ ¼å¼å‘ç”Ÿå˜åŒ–ï¼Œå¦‚æœä½ çš„æ¨¡å‹ä¸‹è½½äº2025å¹´12æœˆ27æ—¥ä¹‹å‰ï¼Œè¯·é‡æ–°æ‹‰å–æœ¬ç‰ˆæœ¬æœ€æ–°æ¨¡å‹ã€‚

## æ¨ç†

æˆ‘ä»¬æä¾›äº†ä¸¤æ®µæµ‹è¯•éŸ³é¢‘ï¼Œåˆ†åˆ«æ˜¯ä¸­æ–‡å’Œè‹±è¯­ç‰ˆæœ¬ã€‚

### ç¯å¢ƒä¾èµ–

```bash
pip install -r requirements.txt
sudo apt install ffmpeg
```

### ç¤ºä¾‹ä»£ç 

+ transformers 5.0.0ï¼Œéœ€æºä»£ç å®‰è£…ï¼Œå‚è€ƒ requirements.txt

```python
from transformers import AutoModel, AutoProcessor
import torch

device = "cuda" if torch.cuda.is_available() else "cpu"
repo_id = "zai-org/GLM-ASR-Nano-2512"

processor = AutoProcessor.from_pretrained(repo_id)
model = AutoModel.from_pretrained(repo_id, dtype=torch.bfloat16, device_map=device)

messages = [
    {
        "role": "user",
        "content": [
            {
                "type": "audio",
                "url": "example_zh.wav",
            },
            {"type": "text", "text": "Please transcribe this audio into text"},
        ],
    }
]

inputs = processor.apply_chat_template(
    messages, tokenize=True, add_generation_prompt=True, return_dict=True, return_tensors="pt"
)
inputs = inputs.to(device, dtype=torch.bfloat16)
outputs = model.generate(**inputs, max_new_tokens=128, do_sample=False)
print(processor.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True))
```

+ SGLang

ç›®å‰ï¼Œæš‚æœªæä¾›å‘è¡Œç‰ˆï¼Œè¯·ä½¿ç”¨æœ€æ–°ç‰ˆæœ¬docker

```shell
docker pull lmsysorg/sglang:dev
```

è¿›å…¥dockerï¼Œè¿è¡Œ

```shell
pip install git+https://github.com/huggingface/transformers # è¦†ç›–transformersç‰ˆæœ¬
python3 -m sglang.launch_server   --model-path /cloud/oss_checkpoints/zai-org/GLM-ASR-Nano-2512 --mem-fraction-static 0.8   --served-model-name glm-asr   --host 0.0.0.0   --port 8000
```

å‘èµ·è¯·æ±‚:

```python
from openai import OpenAI

openai_api_key = "EMPTY"
openai_api_base = "http://127.0.0.1:8000/v1"

client = OpenAI(api_key=openai_api_key, base_url=openai_api_base)
response = client.chat.completions.create(
    model="glm-asr",
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "audio_url",
                    "audio_url": {"url": "example_zh.wav"}
                },
                {
                    "type": "text",
                    "text": "Please transcribe this audio into text"
                },
            ]
        }
    ],
    max_tokens=1024,
)
print(response.choices[0].message.content.strip())
```
+ transformers 4.51.3 (ä½¿ç”¨æœªæ›´æ–°ä¹‹å‰çš„æ¨¡å‹)

```shell
python inference.py --checkpoint_dir zai-org/GLM-ASR-Nano-2512 --audio examples/example_en.wav # è‹±æ–‡
python inference.py --checkpoint_dir zai-org/GLM-ASR-Nano-2512 --audio examples/example_zh.wav # ä¸­æ–‡
```

å¯¹äºä¸Šè¿°ä¸¤æ®µç¤ºä¾‹éŸ³é¢‘ï¼Œæ¨¡å‹èƒ½å¤Ÿç”Ÿæˆå‡†ç¡®çš„è½¬å½•ç»“æœï¼š

```shell
be careful not to allow fabric to become too hot which can cause shrinkage or in extreme cases scorch
æˆ‘è¿˜èƒ½å†æä¸€ä¸ªï¼Œå°±ç®—æ˜¯éå¸¸å°çš„å£°éŸ³ä¹Ÿèƒ½è¯†åˆ«å‡†ç¡®
```
